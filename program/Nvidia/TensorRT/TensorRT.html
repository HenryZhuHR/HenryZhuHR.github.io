<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="generator" content="VuePress 2.0.0-beta.49">
    <style>
      :root {
        --c-bg: #fff;
      }
      html.dark {
        --c-bg: #22272e;
      }
      html, body {
        background-color: var(--c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem('vuepress-color-scheme');
			const systemDarkMode = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;
			if (userMode === 'dark' || (userMode !== 'light' && systemDarkMode)) {
				document.documentElement.classList.toggle('dark', true);
			}
    </script>
    <link rel="icon" type="image/png" sizes="32x32" href="/images/global/avatar-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/global/avatar-16x16.png"><meta name="application-name" content="Henry Zhu"><meta name="apple-mobile-web-app-title" content="Henry Zhu"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="apple-touch-icon" href="/images/global/avatar.png"><meta name="theme-color" content="#377bb5"><meta name="msapplication-TileColor" content="#377bb5"><title>TensorRT | Henry Zhu</title><meta name="description" content="">
    <link rel="modulepreload" href="/assets/app.1fb5ba75.js"><link rel="modulepreload" href="/assets/TensorRT.html.02b2560b.js"><link rel="modulepreload" href="/assets/TensorRT.html.7c1a68eb.js"><link rel="prefetch" href="/assets/resume.html.53206fbb.js"><link rel="prefetch" href="/assets/deeplearning.html.900dbe2b.js"><link rel="prefetch" href="/assets/index.html.7fa7729f.js"><link rel="prefetch" href="/assets/cache.html.cc22c458.js"><link rel="prefetch" href="/assets/mysql.html.757aa34f.js"><link rel="prefetch" href="/assets/obsidian.html.da43a8f8.js"><link rel="prefetch" href="/assets/DiffusionModel.html.ff266689.js"><link rel="prefetch" href="/assets/index.html.dc6a4c9d.js"><link rel="prefetch" href="/assets/basic.html.607c70f4.js"><link rel="prefetch" href="/assets/classification.html.b07b3f02.js"><link rel="prefetch" href="/assets/classifier.html.c708ed5c.js"><link rel="prefetch" href="/assets/cnn.html.3e86ea92.js"><link rel="prefetch" href="/assets/gan.html.1098a83a.js"><link rel="prefetch" href="/assets/FaceAssign.html.cc78d382.js"><link rel="prefetch" href="/assets/Initialization.html.43b78882.js"><link rel="prefetch" href="/assets/MetricLearning.html.56d0ac08.js"><link rel="prefetch" href="/assets/ema.html.f5ab5ce8.js"><link rel="prefetch" href="/assets/mlp.html.0660856e.js"><link rel="prefetch" href="/assets/norm.html.be62fdb1.js"><link rel="prefetch" href="/assets/object_dection.html.dfeb3b23.js"><link rel="prefetch" href="/assets/fine_tune.html.cdd48cf5.js"><link rel="prefetch" href="/assets/pytorch-install.html.2eab0925.js"><link rel="prefetch" href="/assets/train.html.daacd859.js"><link rel="prefetch" href="/assets/index.html.2a86807c.js"><link rel="prefetch" href="/assets/对抗纹理.html.4403d3a2.js"><link rel="prefetch" href="/assets/2019ICML_Zhang_TRADES.html.90f8bbeb.js"><link rel="prefetch" href="/assets/2019_Shafahi_LS.html.161b326c.js"><link rel="prefetch" href="/assets/2020ICML_Rice_RobustOverfitting.html.bd51b19d.js"><link rel="prefetch" href="/assets/2020NIPS_Pang_HE.html.0840be3d.js"><link rel="prefetch" href="/assets/2021CVPR_Luo_Diffusion3DPointCloud.html.1ceea55a.js"><link rel="prefetch" href="/assets/2021ICML_radford_CLIP.html.28ce0e19.js"><link rel="prefetch" href="/assets/AdversarialTraining.html.22036f37.js"><link rel="prefetch" href="/assets/StyleGAN2.html.378b189b.js"><link rel="prefetch" href="/assets/latex.html.de58da1e.js"><link rel="prefetch" href="/assets/backtracking.html.fb6514d9.js"><link rel="prefetch" href="/assets/dp.html.8bacc5fa.js"><link rel="prefetch" href="/assets/monotonic_stack.html.0ce62ff2.js"><link rel="prefetch" href="/assets/wuhan23_sunset.html.66db1c95.js"><link rel="prefetch" href="/assets/多卡训练.html.f5babbd3.js"><link rel="prefetch" href="/assets/index.html.08dfe82b.js"><link rel="prefetch" href="/assets/conda.html.cbf42244.js"><link rel="prefetch" href="/assets/CXX.html.72ffb69d.js"><link rel="prefetch" href="/assets/dl_deploy.html.3452e295.js"><link rel="prefetch" href="/assets/command.html.ebcf3232.js"><link rel="prefetch" href="/assets/git-zhihu.html.6eb6aaf5.js"><link rel="prefetch" href="/assets/git.html.8b2a454b.js"><link rel="prefetch" href="/assets/http.html.3558a6c2.js"><link rel="prefetch" href="/assets/java.html.a71ba7b7.js"><link rel="prefetch" href="/assets/linux-ubuntu.html.c1898321.js"><link rel="prefetch" href="/assets/linux.html.63bce3ca.js"><link rel="prefetch" href="/assets/mosquitto.html.3c5e5f9b.js"><link rel="prefetch" href="/assets/index.html.c46f4d5b.js"><link rel="prefetch" href="/assets/openvino.html.578a8b3a.js"><link rel="prefetch" href="/assets/list.html.4b77e0e7.js"><link rel="prefetch" href="/assets/python.html.fe309a69.js"><link rel="prefetch" href="/assets/ros2.html.69ec61fd.js"><link rel="prefetch" href="/assets/rtmp.html.7c9ab134.js"><link rel="prefetch" href="/assets/ssh.html.3b2f455c.js"><link rel="prefetch" href="/assets/Vue-init.html.8b6620b3.js"><link rel="prefetch" href="/assets/index.html.4136126a.js"><link rel="prefetch" href="/assets/CodiMD.html.484a7e08.js"><link rel="prefetch" href="/assets/PromptEngineering.html.2611a236.js"><link rel="prefetch" href="/assets/QQ-GPT.html.1c3063af.js"><link rel="prefetch" href="/assets/utm串口挂载.html.3517b7d4.js"><link rel="prefetch" href="/assets/BlenderPython.html.b1356ef3.js"><link rel="prefetch" href="/assets/ContentAuthoring-vehicles.html.e853dc67.js"><link rel="prefetch" href="/assets/apis.html.7ca22039.js"><link rel="prefetch" href="/assets/carla-zhihu.html.214dd4fc.js"><link rel="prefetch" href="/assets/carla.html.296a1f02.js"><link rel="prefetch" href="/assets/python-api.html.44711378.js"><link rel="prefetch" href="/assets/retrieve_data.html.7515810e.js"><link rel="prefetch" href="/assets/OpenWRT.html.4d9b86f2.js"><link rel="prefetch" href="/assets/homeAssistant-zhihu.html.a5c3a18a.js"><link rel="prefetch" href="/assets/homeAssistant.html.e68743af.js"><link rel="prefetch" href="/assets/raspberry.html.5433177e.js"><link rel="prefetch" href="/assets/server.html.6105e70a.js"><link rel="prefetch" href="/assets/vscode.html.17c6df65.js"><link rel="prefetch" href="/assets/start.html.9028e430.js"><link rel="prefetch" href="/assets/dataset.html.49ffe26c.js"><link rel="prefetch" href="/assets/index.html.684eff48.js"><link rel="prefetch" href="/assets/diffusion_attack.html.31c4c854.js"><link rel="prefetch" href="/assets/cuda_cudnn.html.2991ff11.js"><link rel="prefetch" href="/assets/cuda.html.14335be5.js"><link rel="prefetch" href="/assets/index.html.1cbe4fcc.js"><link rel="prefetch" href="/assets/JetsonXavierNX-zhihu.html.912da448.js"><link rel="prefetch" href="/assets/jetson_xavier.html.61e2fbef.js"><link rel="prefetch" href="/assets/cmake.html.d476d39e.js"><link rel="prefetch" href="/assets/cxx11.html.146133c7.js"><link rel="prefetch" href="/assets/generics.html.8f216386.js"><link rel="prefetch" href="/assets/lambda.html.80db4c14.js"><link rel="prefetch" href="/assets/rvalue.html.98a24eef.js"><link rel="prefetch" href="/assets/safety_efficiency.html.8b0724b1.js"><link rel="prefetch" href="/assets/smart_ptr.html.db8ca5b2.js"><link rel="prefetch" href="/assets/std_cincout.html.1e4582d5.js"><link rel="prefetch" href="/assets/project.html.6fb8f36a.js"><link rel="prefetch" href="/assets/basic.html.2be0691f.js"><link rel="prefetch" href="/assets/linux-basic.html.cf8137fa.js"><link rel="prefetch" href="/assets/linux-file_system.html.9942e50e.js"><link rel="prefetch" href="/assets/实验1 Linux.html.16c93cc1.js"><link rel="prefetch" href="/assets/实验2 Makefile实验.html.7e41a790.js"><link rel="prefetch" href="/assets/cp.html.667a9262.js"><link rel="prefetch" href="/assets/frp.html.8d62a27a.js"><link rel="prefetch" href="/assets/tmux.html.27822585.js"><link rel="prefetch" href="/assets/ubuntu.html.512f02e5.js"><link rel="prefetch" href="/assets/vim.html.f2381e7f.js"><link rel="prefetch" href="/assets/iterator.html.abb1bb03.js"><link rel="prefetch" href="/assets/list.html.1a74537b.js"><link rel="prefetch" href="/assets/404.html.7d858b3d.js"><link rel="prefetch" href="/assets/index.html.de26035a.js"><link rel="prefetch" href="/assets/index.html.4a704eac.js"><link rel="prefetch" href="/assets/index.html.a04dd3d3.js"><link rel="prefetch" href="/assets/index.html.ff009d80.js"><link rel="prefetch" href="/assets/index.html.2126153c.js"><link rel="prefetch" href="/assets/index.html.f45aae34.js"><link rel="prefetch" href="/assets/index.html.7f48a75e.js"><link rel="prefetch" href="/assets/index.html.07f86cc2.js"><link rel="prefetch" href="/assets/index.html.cf475022.js"><link rel="prefetch" href="/assets/index.html.8111aed0.js"><link rel="prefetch" href="/assets/index.html.76958b33.js"><link rel="prefetch" href="/assets/index.html.881f858e.js"><link rel="prefetch" href="/assets/index.html.f7d705bb.js"><link rel="prefetch" href="/assets/index.html.f55a68b7.js"><link rel="prefetch" href="/assets/index.html.7f012b50.js"><link rel="prefetch" href="/assets/index.html.a4fddea4.js"><link rel="prefetch" href="/assets/index.html.c0ba8663.js"><link rel="prefetch" href="/assets/index.html.78a29513.js"><link rel="prefetch" href="/assets/index.html.fb327772.js"><link rel="prefetch" href="/assets/index.html.bbc9b385.js"><link rel="prefetch" href="/assets/index.html.ea22432c.js"><link rel="prefetch" href="/assets/index.html.140ed163.js"><link rel="prefetch" href="/assets/index.html.e17824b6.js"><link rel="prefetch" href="/assets/index.html.fb4e8b68.js"><link rel="prefetch" href="/assets/index.html.deae5fb3.js"><link rel="prefetch" href="/assets/resume.html.e48574e6.js"><link rel="prefetch" href="/assets/deeplearning.html.1225ff9d.js"><link rel="prefetch" href="/assets/index.html.c0b1bab8.js"><link rel="prefetch" href="/assets/cache.html.60374e00.js"><link rel="prefetch" href="/assets/mysql.html.5e037a43.js"><link rel="prefetch" href="/assets/obsidian.html.66ca0234.js"><link rel="prefetch" href="/assets/DiffusionModel.html.425ffed1.js"><link rel="prefetch" href="/assets/index.html.2db8b0f3.js"><link rel="prefetch" href="/assets/basic.html.96f7e5b0.js"><link rel="prefetch" href="/assets/classification.html.13bd7590.js"><link rel="prefetch" href="/assets/classifier.html.5238874f.js"><link rel="prefetch" href="/assets/cnn.html.052e71bb.js"><link rel="prefetch" href="/assets/gan.html.2e3c7e56.js"><link rel="prefetch" href="/assets/FaceAssign.html.748d4fda.js"><link rel="prefetch" href="/assets/Initialization.html.4682aaec.js"><link rel="prefetch" href="/assets/MetricLearning.html.731fd4ae.js"><link rel="prefetch" href="/assets/ema.html.234b7f4b.js"><link rel="prefetch" href="/assets/mlp.html.18b3d2a6.js"><link rel="prefetch" href="/assets/norm.html.d61d0b9e.js"><link rel="prefetch" href="/assets/object_dection.html.bc2dbff2.js"><link rel="prefetch" href="/assets/fine_tune.html.522acea8.js"><link rel="prefetch" href="/assets/pytorch-install.html.1f9f55c8.js"><link rel="prefetch" href="/assets/train.html.39eaae20.js"><link rel="prefetch" href="/assets/index.html.384ecb1a.js"><link rel="prefetch" href="/assets/对抗纹理.html.675cd90e.js"><link rel="prefetch" href="/assets/2019ICML_Zhang_TRADES.html.fa63a319.js"><link rel="prefetch" href="/assets/2019_Shafahi_LS.html.4e739aad.js"><link rel="prefetch" href="/assets/2020ICML_Rice_RobustOverfitting.html.355b2efa.js"><link rel="prefetch" href="/assets/2020NIPS_Pang_HE.html.14deac41.js"><link rel="prefetch" href="/assets/2021CVPR_Luo_Diffusion3DPointCloud.html.1105c743.js"><link rel="prefetch" href="/assets/2021ICML_radford_CLIP.html.9db95a64.js"><link rel="prefetch" href="/assets/AdversarialTraining.html.55c45d55.js"><link rel="prefetch" href="/assets/StyleGAN2.html.e02299fa.js"><link rel="prefetch" href="/assets/latex.html.5748ac8b.js"><link rel="prefetch" href="/assets/backtracking.html.71a8e7f1.js"><link rel="prefetch" href="/assets/dp.html.5599f434.js"><link rel="prefetch" href="/assets/monotonic_stack.html.f74ad665.js"><link rel="prefetch" href="/assets/wuhan23_sunset.html.02e60c62.js"><link rel="prefetch" href="/assets/多卡训练.html.c2ada95c.js"><link rel="prefetch" href="/assets/index.html.4fcc2287.js"><link rel="prefetch" href="/assets/conda.html.aaab43da.js"><link rel="prefetch" href="/assets/CXX.html.915689e1.js"><link rel="prefetch" href="/assets/dl_deploy.html.a6fa8f30.js"><link rel="prefetch" href="/assets/command.html.df58a4d3.js"><link rel="prefetch" href="/assets/git-zhihu.html.64e9551b.js"><link rel="prefetch" href="/assets/git.html.3c23dc4c.js"><link rel="prefetch" href="/assets/http.html.424d8ac4.js"><link rel="prefetch" href="/assets/java.html.82c669f5.js"><link rel="prefetch" href="/assets/linux-ubuntu.html.a270c573.js"><link rel="prefetch" href="/assets/linux.html.91f017af.js"><link rel="prefetch" href="/assets/mosquitto.html.076e7c4d.js"><link rel="prefetch" href="/assets/index.html.b413234c.js"><link rel="prefetch" href="/assets/openvino.html.99d29623.js"><link rel="prefetch" href="/assets/list.html.fc7936eb.js"><link rel="prefetch" href="/assets/python.html.b505e03e.js"><link rel="prefetch" href="/assets/ros2.html.d617e19d.js"><link rel="prefetch" href="/assets/rtmp.html.b904782b.js"><link rel="prefetch" href="/assets/ssh.html.ee3b63b7.js"><link rel="prefetch" href="/assets/Vue-init.html.a166c82f.js"><link rel="prefetch" href="/assets/index.html.014b3e60.js"><link rel="prefetch" href="/assets/CodiMD.html.c9caf207.js"><link rel="prefetch" href="/assets/PromptEngineering.html.11a24ba8.js"><link rel="prefetch" href="/assets/QQ-GPT.html.c92d0080.js"><link rel="prefetch" href="/assets/utm串口挂载.html.0e76ffb7.js"><link rel="prefetch" href="/assets/BlenderPython.html.124f40d3.js"><link rel="prefetch" href="/assets/ContentAuthoring-vehicles.html.19d243d9.js"><link rel="prefetch" href="/assets/apis.html.fe43bbcb.js"><link rel="prefetch" href="/assets/carla-zhihu.html.c23f9f0f.js"><link rel="prefetch" href="/assets/carla.html.8b1e4173.js"><link rel="prefetch" href="/assets/python-api.html.ed657aed.js"><link rel="prefetch" href="/assets/retrieve_data.html.2e7c3bc3.js"><link rel="prefetch" href="/assets/OpenWRT.html.ceab42e3.js"><link rel="prefetch" href="/assets/homeAssistant-zhihu.html.2f561469.js"><link rel="prefetch" href="/assets/homeAssistant.html.eaa895e3.js"><link rel="prefetch" href="/assets/raspberry.html.31090196.js"><link rel="prefetch" href="/assets/server.html.c731fc4e.js"><link rel="prefetch" href="/assets/vscode.html.57973de6.js"><link rel="prefetch" href="/assets/start.html.b70033f1.js"><link rel="prefetch" href="/assets/dataset.html.f6e3fe4a.js"><link rel="prefetch" href="/assets/index.html.3686085e.js"><link rel="prefetch" href="/assets/diffusion_attack.html.13668710.js"><link rel="prefetch" href="/assets/cuda_cudnn.html.ddbe56d0.js"><link rel="prefetch" href="/assets/cuda.html.e9dc6706.js"><link rel="prefetch" href="/assets/index.html.c4b670d9.js"><link rel="prefetch" href="/assets/JetsonXavierNX-zhihu.html.0be6e5c6.js"><link rel="prefetch" href="/assets/jetson_xavier.html.bd619c6f.js"><link rel="prefetch" href="/assets/cmake.html.248e928b.js"><link rel="prefetch" href="/assets/cxx11.html.ddd3a88a.js"><link rel="prefetch" href="/assets/generics.html.8fcf68cf.js"><link rel="prefetch" href="/assets/lambda.html.3fe1bd40.js"><link rel="prefetch" href="/assets/rvalue.html.c2fb5b6f.js"><link rel="prefetch" href="/assets/safety_efficiency.html.05a4e6e3.js"><link rel="prefetch" href="/assets/smart_ptr.html.fe57783c.js"><link rel="prefetch" href="/assets/std_cincout.html.f1bec547.js"><link rel="prefetch" href="/assets/project.html.2e3b40f3.js"><link rel="prefetch" href="/assets/basic.html.fd30def3.js"><link rel="prefetch" href="/assets/linux-basic.html.6830436b.js"><link rel="prefetch" href="/assets/linux-file_system.html.6da19d1d.js"><link rel="prefetch" href="/assets/实验1 Linux.html.a11af111.js"><link rel="prefetch" href="/assets/实验2 Makefile实验.html.a3b71f6d.js"><link rel="prefetch" href="/assets/cp.html.9040d6bc.js"><link rel="prefetch" href="/assets/frp.html.ce82b505.js"><link rel="prefetch" href="/assets/tmux.html.d5f5e130.js"><link rel="prefetch" href="/assets/ubuntu.html.f7ee4451.js"><link rel="prefetch" href="/assets/vim.html.c0ef2880.js"><link rel="prefetch" href="/assets/iterator.html.2ca03510.js"><link rel="prefetch" href="/assets/list.html.28a5f3da.js"><link rel="prefetch" href="/assets/404.html.87e00b85.js"><link rel="prefetch" href="/assets/index.html.ccbe8487.js"><link rel="prefetch" href="/assets/index.html.5931f721.js"><link rel="prefetch" href="/assets/index.html.906f1457.js"><link rel="prefetch" href="/assets/index.html.fcb50a93.js"><link rel="prefetch" href="/assets/index.html.fee43d45.js"><link rel="prefetch" href="/assets/index.html.9f5237d2.js"><link rel="prefetch" href="/assets/index.html.b8630435.js"><link rel="prefetch" href="/assets/index.html.add65193.js"><link rel="prefetch" href="/assets/index.html.01b0a4dd.js"><link rel="prefetch" href="/assets/index.html.74e7f304.js"><link rel="prefetch" href="/assets/index.html.a11931dc.js"><link rel="prefetch" href="/assets/index.html.f53c25d5.js"><link rel="prefetch" href="/assets/index.html.bdb46eef.js"><link rel="prefetch" href="/assets/index.html.c1baef6a.js"><link rel="prefetch" href="/assets/index.html.5fc1ea96.js"><link rel="prefetch" href="/assets/index.html.6c011b4e.js"><link rel="prefetch" href="/assets/index.html.b8fd324c.js"><link rel="prefetch" href="/assets/index.html.fcb164b6.js"><link rel="prefetch" href="/assets/index.html.3f54f86e.js"><link rel="prefetch" href="/assets/index.html.ed9c37e8.js"><link rel="prefetch" href="/assets/index.html.275e2cc5.js"><link rel="prefetch" href="/assets/index.html.240c73bc.js"><link rel="prefetch" href="/assets/index.html.052cc0cf.js"><link rel="prefetch" href="/assets/index.html.ca41ea81.js"><link rel="prefetch" href="/assets/index.html.534dec5f.js"><link rel="prefetch" href="/assets/404.16d66b7c.js"><link rel="prefetch" href="/assets/HomePage.d3d5ae3a.js"><link rel="prefetch" href="/assets/Layout.3aa49bef.js"><link rel="prefetch" href="/assets/Links.7e6398f7.js"><link rel="prefetch" href="/assets/Post.4b015b33.js"><link rel="prefetch" href="/assets/Tags.32564d31.js">
    <link rel="stylesheet" href="/assets/style.d4b70036.css">
  </head>
  <body>
    <div id="app"><!--[--><div class="theme-container no-sidebar"><!--[--><header class="navbar invert"><span><a href="/" class=""><span class="site-name">$ cd /home/henryzhu</span></a></span><div class="navbar-items-wrapper" style=""><!--[--><!--]--><nav class="navbar-items can-hide"><!--[--><div class="navbar-item"><a href="/" class="" aria-label="主页/Home"><!--[--><!--]--><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewBox="0.48 0.48 23.04 23.04" fill="currentColor"><path fill="none" d="M0 0h24v24H0z"/><path d="M10 20v-6h4v6h5v-8h3L12 3 2 12h3v8z"/></svg></span><span>主页/Home</span><!--[--><!--]--></a></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="开发/Develop"><span class="title"><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewBox="-1.6 -1.6 19.2 19.2" fill="currentColor"><path fill-rule="evenodd" d="M14.064 0a8.75 8.75 0 00-6.187 2.563l-.459.458c-.314.314-.616.641-.904.979H3.31a1.75 1.75 0 00-1.49.833L.11 7.607a.75.75 0 00.418 1.11l3.102.954c.037.051.079.1.124.145l2.429 2.428c.046.046.094.088.145.125l.954 3.102a.75.75 0 001.11.418l2.774-1.707a1.75 1.75 0 00.833-1.49V9.485c.338-.288.665-.59.979-.904l.458-.459A8.75 8.75 0 0016 1.936V1.75A1.75 1.75 0 0014.25 0h-.186zM10.5 10.625c-.088.06-.177.118-.266.175l-2.35 1.521.548 1.783 1.949-1.2a.25.25 0 00.119-.213v-2.066zM3.678 8.116L5.2 5.766c.058-.09.117-.178.176-.266H3.309a.25.25 0 00-.213.119l-1.2 1.95 1.782.547zm5.26-4.493A7.25 7.25 0 0114.063 1.5h.186a.25.25 0 01.25.25v.186a7.25 7.25 0 01-2.123 5.127l-.459.458a15.21 15.21 0 01-2.499 2.02l-2.317 1.5-2.143-2.143 1.5-2.317a15.25 15.25 0 012.02-2.5l.458-.458h.002zM12 5a1 1 0 11-2 0 1 1 0 012 0zm-8.44 9.56a1.5 1.5 0 10-2.12-2.12c-.734.73-1.047 2.332-1.15 3.003a.23.23 0 00.265.265c.671-.103 2.273-.416 3.005-1.148z"/></svg></span><span>开发/Develop</span></span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="开发/Develop"><span class="title"><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewBox="-1.6 -1.6 19.2 19.2" fill="currentColor"><path fill-rule="evenodd" d="M14.064 0a8.75 8.75 0 00-6.187 2.563l-.459.458c-.314.314-.616.641-.904.979H3.31a1.75 1.75 0 00-1.49.833L.11 7.607a.75.75 0 00.418 1.11l3.102.954c.037.051.079.1.124.145l2.429 2.428c.046.046.094.088.145.125l.954 3.102a.75.75 0 001.11.418l2.774-1.707a1.75 1.75 0 00.833-1.49V9.485c.338-.288.665-.59.979-.904l.458-.459A8.75 8.75 0 0016 1.936V1.75A1.75 1.75 0 0014.25 0h-.186zM10.5 10.625c-.088.06-.177.118-.266.175l-2.35 1.521.548 1.783 1.949-1.2a.25.25 0 00.119-.213v-2.066zM3.678 8.116L5.2 5.766c.058-.09.117-.178.176-.266H3.309a.25.25 0 00-.213.119l-1.2 1.95 1.782.547zm5.26-4.493A7.25 7.25 0 0114.063 1.5h.186a.25.25 0 01.25.25v.186a7.25 7.25 0 01-2.123 5.127l-.459.458a15.21 15.21 0 01-2.499 2.02l-2.317 1.5-2.143-2.143 1.5-2.317a15.25 15.25 0 012.02-2.5l.458-.458h.002zM12 5a1 1 0 11-2 0 1 1 0 012 0zm-8.44 9.56a1.5 1.5 0 10-2.12-2.12c-.734.73-1.047 2.332-1.15 3.003a.23.23 0 00.265.265c.671-.103 2.273-.416 3.005-1.148z"/></svg></span><span>开发/Develop</span></span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a href="/program/linux/linux.md" class="" aria-label="Linux Go!"><!--[--><!--]--><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewBox="0.48 0.48 23.04 23.04" fill="currentColor"><path fill="none" d="M0 0h24v24H0z"/><path d="M20 4H4a2 2 0 00-2 2v12a2 2 0 002 2h16c1.1 0 2-.9 2-2V6a2 2 0 00-2-2zm0 14H4V8h16v10zm-2-1h-6v-2h6v2zM7.5 17l-1.41-1.41L8.67 13l-2.59-2.59L7.5 9l4 4-4 4z"/></svg></span><span>Linux Go!</span><!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/program/git/git.md" class="" aria-label="Git"><!--[--><!--]--><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewBox="0.48 0.48 23.04 23.04" fill="currentColor"><path fill="none" d="M0 0h24v24H0z"/><path d="M12 4V1L8 5l4 4V6c3.31 0 6 2.69 6 6 0 1.01-.25 1.97-.7 2.8l1.46 1.46A7.93 7.93 0 0020 12c0-4.42-3.58-8-8-8zm0 14c-3.31 0-6-2.69-6-6 0-1.01.25-1.97.7-2.8L5.24 7.74A7.93 7.93 0 004 12c0 4.42 3.58 8 8 8v3l4-4-4-4v3z"/></svg></span><span>Git</span><!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/program/ssh/ssh.md" class="" aria-label="SSH"><!--[--><!--]--><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewBox="-1.6 -1.6 19.2 19.2" fill="currentColor"><path fill-rule="evenodd" d="M6.5 5.5a4 4 0 112.731 3.795.75.75 0 00-.768.18L7.44 10.5H6.25a.75.75 0 00-.75.75v1.19l-.06.06H4.25a.75.75 0 00-.75.75v1.19l-.06.06H1.75a.25.25 0 01-.25-.25v-1.69l5.024-5.023a.75.75 0 00.181-.768A3.995 3.995 0 016.5 5.5zm4-5.5a5.5 5.5 0 00-5.348 6.788L.22 11.72a.75.75 0 00-.22.53v2C0 15.216.784 16 1.75 16h2a.75.75 0 00.53-.22l.5-.5a.75.75 0 00.22-.53V14h.75a.75.75 0 00.53-.22l.5-.5a.75.75 0 00.22-.53V12h.75a.75.75 0 00.53-.22l.932-.932A5.5 5.5 0 1010.5 0zm.5 6a1 1 0 100-2 1 1 0 000 2z"/></svg></span><span>SSH</span><!--[--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-item"><a href="/links/" class="" aria-label="分类/Links"><!--[--><!--]--><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewBox="-43.52 -43.52 599.04 599.04" fill="currentColor"><path d="M305.45 462.59c7.391 7.298 6.188 20.097-3 25.004-77.714 41.802-176.726 29.91-242.344-35.709-65.602-65.603-77.51-164.523-35.692-242.331 4.891-9.095 17.69-10.298 25.003-3l116.812 116.813 27.394-27.394c-.688-2.61-1.594-5.001-1.594-7.814a32.004 32.004 0 1132.004 32.005c-2.797 0-5.204-.891-7.798-1.594l-27.41 27.41zm206.526-159.523a16.103 16.103 0 01-16.002 17.003H463.86a15.97 15.97 0 01-15.892-15.002C440.467 175.549 336.453 70.534 207.03 63.533a15.845 15.845 0 01-15.002-15.908V16.027A16.094 16.094 0 01209.03.024C372.255 8.62 503.475 139.841 511.976 303.067zm-96.012-.297a16.21 16.21 0 01-16.112 17.3h-32.207a16.069 16.069 0 01-15.893-14.705c-6.907-77.011-68.118-138.91-144.924-145.224a15.94 15.94 0 01-14.8-15.893v-32.114a16.134 16.134 0 0117.3-16.096c110.123 8.501 198.228 96.607 206.636 206.732z"/></svg></span><span>分类/Links</span><!--[--><!--]--></a></div><div class="navbar-item"><a href="/tags/" class="" aria-label="标签/Tags"><!--[--><!--]--><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewBox="-43.52 -43.52 599.04 599.04" fill="currentColor"><path d="M0 252.118V48C0 21.49 21.49 0 48 0h204.118a48 48 0 0133.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882L293.823 497.941c-18.745 18.745-49.137 18.745-67.882 0L14.059 286.059A48 48 0 010 252.118zM112 64c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48z"/></svg></span><span>标签/Tags</span><!--[--><!--]--></a></div><!--]--><div class="navbar-item"><a style="cursor:pointer;"><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewBox="0 0 24 24" fill="currentColor"><path fill="none" d="M0 0h24v24H0z"/><path d="M11 2c4.968 0 9 4.032 9 9s-4.032 9-9 9-9-4.032-9-9 4.032-9 9-9zm0 16c3.867 0 7-3.133 7-7 0-3.868-3.133-7-7-7-3.868 0-7 3.132-7 7 0 3.867 3.132 7 7 7zm8.485.071l2.829 2.828-1.415 1.415-2.828-2.829 1.414-1.414z"/></svg></span><span>Search</span></a></div></nav><!--[--><!--]--><!----></div></header><!--]--><div class="sidebar-mask"></div><!--[--><aside class="sidebar"><nav class="navbar-items"><!--[--><div class="navbar-item"><a href="/" class="" aria-label="主页/Home"><!--[--><!--]--><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewBox="0.48 0.48 23.04 23.04" fill="currentColor"><path fill="none" d="M0 0h24v24H0z"/><path d="M10 20v-6h4v6h5v-8h3L12 3 2 12h3v8z"/></svg></span><span>主页/Home</span><!--[--><!--]--></a></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="开发/Develop"><span class="title"><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewBox="-1.6 -1.6 19.2 19.2" fill="currentColor"><path fill-rule="evenodd" d="M14.064 0a8.75 8.75 0 00-6.187 2.563l-.459.458c-.314.314-.616.641-.904.979H3.31a1.75 1.75 0 00-1.49.833L.11 7.607a.75.75 0 00.418 1.11l3.102.954c.037.051.079.1.124.145l2.429 2.428c.046.046.094.088.145.125l.954 3.102a.75.75 0 001.11.418l2.774-1.707a1.75 1.75 0 00.833-1.49V9.485c.338-.288.665-.59.979-.904l.458-.459A8.75 8.75 0 0016 1.936V1.75A1.75 1.75 0 0014.25 0h-.186zM10.5 10.625c-.088.06-.177.118-.266.175l-2.35 1.521.548 1.783 1.949-1.2a.25.25 0 00.119-.213v-2.066zM3.678 8.116L5.2 5.766c.058-.09.117-.178.176-.266H3.309a.25.25 0 00-.213.119l-1.2 1.95 1.782.547zm5.26-4.493A7.25 7.25 0 0114.063 1.5h.186a.25.25 0 01.25.25v.186a7.25 7.25 0 01-2.123 5.127l-.459.458a15.21 15.21 0 01-2.499 2.02l-2.317 1.5-2.143-2.143 1.5-2.317a15.25 15.25 0 012.02-2.5l.458-.458h.002zM12 5a1 1 0 11-2 0 1 1 0 012 0zm-8.44 9.56a1.5 1.5 0 10-2.12-2.12c-.734.73-1.047 2.332-1.15 3.003a.23.23 0 00.265.265c.671-.103 2.273-.416 3.005-1.148z"/></svg></span><span>开发/Develop</span></span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="开发/Develop"><span class="title"><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewBox="-1.6 -1.6 19.2 19.2" fill="currentColor"><path fill-rule="evenodd" d="M14.064 0a8.75 8.75 0 00-6.187 2.563l-.459.458c-.314.314-.616.641-.904.979H3.31a1.75 1.75 0 00-1.49.833L.11 7.607a.75.75 0 00.418 1.11l3.102.954c.037.051.079.1.124.145l2.429 2.428c.046.046.094.088.145.125l.954 3.102a.75.75 0 001.11.418l2.774-1.707a1.75 1.75 0 00.833-1.49V9.485c.338-.288.665-.59.979-.904l.458-.459A8.75 8.75 0 0016 1.936V1.75A1.75 1.75 0 0014.25 0h-.186zM10.5 10.625c-.088.06-.177.118-.266.175l-2.35 1.521.548 1.783 1.949-1.2a.25.25 0 00.119-.213v-2.066zM3.678 8.116L5.2 5.766c.058-.09.117-.178.176-.266H3.309a.25.25 0 00-.213.119l-1.2 1.95 1.782.547zm5.26-4.493A7.25 7.25 0 0114.063 1.5h.186a.25.25 0 01.25.25v.186a7.25 7.25 0 01-2.123 5.127l-.459.458a15.21 15.21 0 01-2.499 2.02l-2.317 1.5-2.143-2.143 1.5-2.317a15.25 15.25 0 012.02-2.5l.458-.458h.002zM12 5a1 1 0 11-2 0 1 1 0 012 0zm-8.44 9.56a1.5 1.5 0 10-2.12-2.12c-.734.73-1.047 2.332-1.15 3.003a.23.23 0 00.265.265c.671-.103 2.273-.416 3.005-1.148z"/></svg></span><span>开发/Develop</span></span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a href="/program/linux/linux.md" class="" aria-label="Linux Go!"><!--[--><!--]--><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewBox="0.48 0.48 23.04 23.04" fill="currentColor"><path fill="none" d="M0 0h24v24H0z"/><path d="M20 4H4a2 2 0 00-2 2v12a2 2 0 002 2h16c1.1 0 2-.9 2-2V6a2 2 0 00-2-2zm0 14H4V8h16v10zm-2-1h-6v-2h6v2zM7.5 17l-1.41-1.41L8.67 13l-2.59-2.59L7.5 9l4 4-4 4z"/></svg></span><span>Linux Go!</span><!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/program/git/git.md" class="" aria-label="Git"><!--[--><!--]--><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewBox="0.48 0.48 23.04 23.04" fill="currentColor"><path fill="none" d="M0 0h24v24H0z"/><path d="M12 4V1L8 5l4 4V6c3.31 0 6 2.69 6 6 0 1.01-.25 1.97-.7 2.8l1.46 1.46A7.93 7.93 0 0020 12c0-4.42-3.58-8-8-8zm0 14c-3.31 0-6-2.69-6-6 0-1.01.25-1.97.7-2.8L5.24 7.74A7.93 7.93 0 004 12c0 4.42 3.58 8 8 8v3l4-4-4-4v3z"/></svg></span><span>Git</span><!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/program/ssh/ssh.md" class="" aria-label="SSH"><!--[--><!--]--><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewBox="-1.6 -1.6 19.2 19.2" fill="currentColor"><path fill-rule="evenodd" d="M6.5 5.5a4 4 0 112.731 3.795.75.75 0 00-.768.18L7.44 10.5H6.25a.75.75 0 00-.75.75v1.19l-.06.06H4.25a.75.75 0 00-.75.75v1.19l-.06.06H1.75a.25.25 0 01-.25-.25v-1.69l5.024-5.023a.75.75 0 00.181-.768A3.995 3.995 0 016.5 5.5zm4-5.5a5.5 5.5 0 00-5.348 6.788L.22 11.72a.75.75 0 00-.22.53v2C0 15.216.784 16 1.75 16h2a.75.75 0 00.53-.22l.5-.5a.75.75 0 00.22-.53V14h.75a.75.75 0 00.53-.22l.5-.5a.75.75 0 00.22-.53V12h.75a.75.75 0 00.53-.22l.932-.932A5.5 5.5 0 1010.5 0zm.5 6a1 1 0 100-2 1 1 0 000 2z"/></svg></span><span>SSH</span><!--[--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-item"><a href="/links/" class="" aria-label="分类/Links"><!--[--><!--]--><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewBox="-43.52 -43.52 599.04 599.04" fill="currentColor"><path d="M305.45 462.59c7.391 7.298 6.188 20.097-3 25.004-77.714 41.802-176.726 29.91-242.344-35.709-65.602-65.603-77.51-164.523-35.692-242.331 4.891-9.095 17.69-10.298 25.003-3l116.812 116.813 27.394-27.394c-.688-2.61-1.594-5.001-1.594-7.814a32.004 32.004 0 1132.004 32.005c-2.797 0-5.204-.891-7.798-1.594l-27.41 27.41zm206.526-159.523a16.103 16.103 0 01-16.002 17.003H463.86a15.97 15.97 0 01-15.892-15.002C440.467 175.549 336.453 70.534 207.03 63.533a15.845 15.845 0 01-15.002-15.908V16.027A16.094 16.094 0 01209.03.024C372.255 8.62 503.475 139.841 511.976 303.067zm-96.012-.297a16.21 16.21 0 01-16.112 17.3h-32.207a16.069 16.069 0 01-15.893-14.705c-6.907-77.011-68.118-138.91-144.924-145.224a15.94 15.94 0 01-14.8-15.893v-32.114a16.134 16.134 0 0117.3-16.096c110.123 8.501 198.228 96.607 206.636 206.732z"/></svg></span><span>分类/Links</span><!--[--><!--]--></a></div><div class="navbar-item"><a href="/tags/" class="" aria-label="标签/Tags"><!--[--><!--]--><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewBox="-43.52 -43.52 599.04 599.04" fill="currentColor"><path d="M0 252.118V48C0 21.49 21.49 0 48 0h204.118a48 48 0 0133.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882L293.823 497.941c-18.745 18.745-49.137 18.745-67.882 0L14.059 286.059A48 48 0 010 252.118zM112 64c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48z"/></svg></span><span>标签/Tags</span><!--[--><!--]--></a></div><!--]--><div class="navbar-item"><a style="cursor:pointer;"><span class="nav-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewBox="0 0 24 24" fill="currentColor"><path fill="none" d="M0 0h24v24H0z"/><path d="M11 2c4.968 0 9 4.032 9 9s-4.032 9-9 9-9-4.032-9-9 4.032-9 9-9zm0 16c3.867 0 7-3.133 7-7 0-3.868-3.133-7-7-7-3.868 0-7 3.132-7 7 0 3.867 3.132 7 7 7zm8.485.071l2.829 2.828-1.415 1.415-2.828-2.829 1.414-1.414z"/></svg></span><span>Search</span></a></div></nav><!--[--><!--]--><!----><!--[--><!--]--></aside><!--]--><div class="page-content"><!--[--><div class="show-catalog post-wrapper"><div class="article-header use-image post-header" style="background-image:url(/images/backgrounds/anthony-martin-mabillestyle-iii-export.jpg);"><div class="article-header-mask" style="background:rgb(0,0,0, .5);"></div><div class="article-header-content"><div class="article-tags"><!--[--><a href="/tags/deep-learning/" class="article-tag">deep-learning</a><a href="/tags/nvidia/" class="article-tag">nvidia</a><a href="/tags/tensorrt/" class="article-tag">tensorrt</a><!--]--></div><h1 class="article-title">TensorRT</h1><p class="article-subtitle">TensorRT</p><div class="article-icons"><div class="article-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewBox="-75.52 -43.52 599.04 599.04" fill="currentColor"><path d="M313.6 304c-28.7 0-42.5 16-89.6 16-47.1 0-60.8-16-89.6-16C60.2 304 0 364.2 0 438.4V464c0 26.5 21.5 48 48 48h352c26.5 0 48-21.5 48-48v-25.6c0-74.2-60.2-134.4-134.4-134.4zM400 464H48v-25.6c0-47.6 38.8-86.4 86.4-86.4 14.6 0 38.3 16 89.6 16 51.7 0 74.9-16 89.6-16 47.6 0 86.4 38.8 86.4 86.4V464zM224 288c79.5 0 144-64.5 144-144S303.5 0 224 0 80 64.5 80 144s64.5 144 144 144zm0-240c52.9 0 96 43.1 96 96s-43.1 96-96 96-96-43.1-96-96 43.1-96 96-96z"/></svg><span>HenryZhu</span></div><div class="article-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewBox="-75.52 -43.52 599.04 599.04" fill="currentColor"><path d="M400 64h-48V12c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v52H160V12c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v52H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h352c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zm-6 400H54c-3.3 0-6-2.7-6-6V160h352v298c0 3.3-2.7 6-6 6z"/></svg><span>2023-03-25</span></div><div class="article-icon"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewBox="0 0 24 24" fill="currentColor"><path fill="none" d="M0 0h24v24H0z"/><path d="M17.618 5.968l1.453-1.453 1.414 1.414-1.453 1.453a9 9 0 11-1.414-1.414zM12 20a7 7 0 100-14 7 7 0 000 14zM11 8h2v6h-2V8zM8 1h8v2H8V1z"/></svg><span>12 min</span></div></div></div><!----></div><main class="page post-content"><!--[--><!--]--><div class="theme-gungnir-content"><!--[--><!--]--><div><h1 id="tensorrt" tabindex="-1"><a class="header-anchor" href="#tensorrt" aria-hidden="true">#</a> TensorRT</h1><h2 id="什么是-tensorrt" tabindex="-1"><a class="header-anchor" href="#什么是-tensorrt" aria-hidden="true">#</a> 什么是 TensorRT</h2><p>NVIDIA TensorRT™ 是用于高性能深度学习推理的 SDK。此 SDK 包含深度学习推理优化器和运行时环境，可为深度学习推理应用提供低延迟和高吞吐量。</p><p><a href="https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#python_example_unsupported" target="_blank" rel="noopener noreferrer">TensorRT Documentation</a></p><h2 id="安装" tabindex="-1"><a class="header-anchor" href="#安装" aria-hidden="true">#</a> 安装</h2><p><a href="https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html" target="_blank" rel="noopener noreferrer">Installing TensorRT</a></p><ul><li>确保 NVIDIA CUDA™ Toolkit 已经安装；支持的 CUDA 版本可以在 <a href="https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html#gettingstarted" target="_blank" rel="noopener noreferrer">Getting Started</a> 中找到</li><li>cuDNN 是可选的</li></ul><p>这里采用 <a href="https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html#installing-tar" target="_blank" rel="noopener noreferrer">Tar File Installation</a> 的安装方式，因为配置 <code>LD_LIBRARY_PATH</code> 即可，比较灵活</p><p>下载地址（进入 Get Started） https://developer.nvidia.com/tensorrt</p><p>解压后得到 <code>TensorRT-${version}</code></p><div class="language-text ext-text line-numbers-mode"><pre class="language-text"><code>version=&quot;8.x.x.x&quot;
arch=$(uname -m)
cuda=&quot;cuda-x.x&quot;
tar -xzvf TensorRT-${version}.Linux.${arch}-gnu.${cuda}.tar.gz
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>路径添加到环境变量 <code>.bashrc</code></p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code><span class="token builtin class-name">export</span> <span class="token assign-left variable">LD_LIBRARY_PATH</span><span class="token operator">=</span><span class="token variable">$LD_LIBRARY_PATH</span>:<span class="token operator">&lt;</span>path-to-TensorRT-<span class="token variable">${version}</span>/lib<span class="token operator">&gt;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code><span class="token builtin class-name">cd</span> TensorRT-<span class="token variable">${version}</span>/python
python3 <span class="token parameter variable">-m</span> pip <span class="token function">install</span> tensorrt-*-cp3x-none-linux_x86_64.whl
<span class="token comment"># (optinal)</span>
python3 <span class="token parameter variable">-m</span> pip <span class="token function">install</span> tensorrt_lean-*-cp3x-none-linux_x86_64.whl
python3 <span class="token parameter variable">-m</span> pip <span class="token function">install</span> tensorrt_dispatch-*-cp3x-none-linux_x86_64.whl
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="onnx-部署" tabindex="-1"><a class="header-anchor" href="#onnx-部署" aria-hidden="true">#</a> ONNX 部署</h2><p><a href="https://docs.nvidia.com/deeplearning/tensorrt/quick-start-guide/index.html#ex-deploy-onnx" target="_blank" rel="noopener noreferrer">Example Deployment Using ONNX</a></p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code><span class="token assign-left variable">BATCH_SIZE</span><span class="token operator">=</span><span class="token number">64</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h2 id="部署" tabindex="-1"><a class="header-anchor" href="#部署" aria-hidden="true">#</a> 部署</h2><p>部署分为两种方式：</p><ol><li><strong>ONNX 部署</strong>：将 pytorch 模型转化为 ONNX 模型，然后使用 ONNXRuntime 进行推理</li><li><strong>TensorRT 部署</strong>：：将 pytorch 模型转化为 ONNX/Engine 模型，然后使用 TensorRT 进行推理</li></ol><p>这里给出一种推理速度参考</p><table><thead><tr><th style="text-align:center;">推理方式</th><th style="text-align:center;">平均推理时间</th></tr></thead><tbody><tr><td style="text-align:center;">Pytorch</td><td style="text-align:center;">30.9649 ms</td></tr><tr><td style="text-align:center;">ONNXRuntime</td><td style="text-align:center;">19.9175 ms</td></tr><tr><td style="text-align:center;">TensorRT Engine</td><td style="text-align:center;">6.5350 ms</td></tr></tbody></table><p>TensorRT 部署在 Jetson 上需要考虑系统环境，例如 <a href="https://developer.nvidia.com/embedded/jetson-nano-developer-kit" target="_blank" rel="noopener noreferrer">Jetson Nano</a> 系统中包含<a href="https://developer.nvidia.com/embedded/jetpack-sdk-461" target="_blank" rel="noopener noreferrer">JetPack 4.6.1</a>:</p><ul><li><strong>OS</strong>: Ubuntu 18.04, Linux kernel 4.9</li><li><a href="https://docs.nvidia.com/deeplearning/tensorrt/archives/tensorrt-821/quick-start-guide/index.html" target="_blank" rel="noopener noreferrer"><strong>TensorRT 8.2.1</strong></a></li><li><strong>cuDNN 8.2.1</strong></li><li><a href="https://docs.nvidia.com/cuda/archive/10.2/cuda-toolkit-release-notes/index.html#title-new-features" target="_blank" rel="noopener noreferrer"><strong>CUDA 10.2</strong></a></li></ul><h3 id="_1-onnx-部署" tabindex="-1"><a class="header-anchor" href="#_1-onnx-部署" aria-hidden="true">#</a> 1. ONNX 部署</h3><h3 id="_2-tensorrt-部署" tabindex="-1"><a class="header-anchor" href="#_2-tensorrt-部署" aria-hidden="true">#</a> 2. TensorRT 部署</h3><blockquote><p>Ubuntu + Nvidia GPU 环境 。Windows 也不是不行，就是不想配置 Win 中环境变量而已</p></blockquote><p>参考 <a href="https://docs.nvidia.com/deeplearning/tensorrt/archives/index.html#trt_8" target="_blank" rel="noopener noreferrer">TensorRT 官方文档</a>，部署有两种方式：</p><ol><li>使用 TensorRT 推理 ONNX 模型</li><li>将 ONNX 转化为 Engine 模型并使用 TensorRT 推理</li></ol><p>TensorRT官方文档 <a href="https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html" target="_blank" rel="noopener noreferrer">&quot;NVIDIA Official Documentation&quot;</a></p><ul><li><a href="https://docs.nvidia.com/deeplearning/tensorrt/api/python_api/index.html" target="_blank" rel="noopener noreferrer">TensorRT Python API.</a></li><li><a href="https://docs.nvidia.com/deeplearning/tensorrt/api/c_api/index.html" target="_blank" rel="noopener noreferrer">TensorRT C++ API.</a></li></ul><h4 id="安装-tensorrt-环境" tabindex="-1"><a class="header-anchor" href="#安装-tensorrt-环境" aria-hidden="true">#</a> 安装 TensorRT 环境</h4><p>必须 Ubuntu + Nvidia GPU 环境</p><ol><li>安装 CUDA、cuDNN、TensorRT，参考<a href="https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html#installing-tar" target="_blank" rel="noopener noreferrer">官方文档</a>，需要注册 <a href="https://developer.nvidia.cn/login" target="_blank" rel="noopener noreferrer">Nvidia 账号</a>，并登陆</li></ol><ul><li><p><strong>安装 CUDA</strong></p><p>进入<a href="https://developer.nvidia.com/cuda-toolkit-archive" target="_blank" rel="noopener noreferrer">CUDA 下载页面</a>并选择需要的版本，根据电脑的配置依次选择各项，最后选择 <code>deb(local)</code>安装方式，将出现的命令依次复制到终端中执行。</p><p><strong>注意</strong>: JetPack 4.6.1 <a href="https://developer.nvidia.com/cuda-10.2-download-archive" target="_blank" rel="noopener noreferrer">CUDA 10.2</a>，但是 10.2 不支持 Ubuntu20，所以下载 <a href="https://developer.nvidia.com/cuda-11-4-0-download-archive" target="_blank" rel="noopener noreferrer">CUDA 11.4</a></p></li><li><p><strong>安装 cuDNN</strong></p><p>进入<a href="https://developer.nvidia.com/rdp/cudnn-archive" target="_blank" rel="noopener noreferrer">cuDNN 下载页面</a>，根据 <strong>CUDA 版本</strong>和<strong>系统架构</strong>选择对应的版本的 <strong>Tar</strong>文件，下载以下内文件：</p><ul><li><a href="https://developer.nvidia.com/compute/machine-learning/cudnn/secure/8.2.1.32/10.2_06072021/cudnn-10.2-linux-x64-v8.2.1.32.tgz" target="_blank" rel="noopener noreferrer"><code>cuDNN v8.2.1, for CUDA 10.2, for Linux (x86)</code></a>: 安装在 Jetson Nano 上用于转换 Engine 模型</li><li><a href="https://developer.nvidia.com/compute/machine-learning/cudnn/secure/8.2.1.32/11.3_06072021/cudnn-11.3-linux-x64-v8.2.1.32.tgz" target="_blank" rel="noopener noreferrer"><code>cuDNN v8.2.1, for CUDA 11.x, for Linux (x86)</code></a>: 安装在电脑上用于转换 Engine 模型和测试，这一步是为了在电脑上编写推理代码和测试，如果推理代码已经写好，可以不用安装</li><li><a href="https://developer.nvidia.com/downloads/compute/cudnn/secure/8.9.0/local_installers/11.8/cudnn-linux-x86_64-8.9.0.131_cuda11-archive.tar.xz/" target="_blank" rel="noopener noreferrer"><code>cuDNN8.9.0 + CUDA 11.8 + Linux x86_64 (Tar)</code></a>: 最新版本</li></ul><p>下载后得到压缩包 <code>cudnn-${version}.tar.xz</code> ，将压缩包解压后得到同名的目录，但是8.2.1 解压后得到的是 cuda 目录，建议改名</p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code><span class="token function">tar</span> <span class="token parameter variable">-xf</span> cudnn-<span class="token variable">${version}</span>.tar.xz
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div></li><li><p><strong>安装 TensorRT</strong></p><p>进入<a href="https://developer.nvidia.com/tensorrt-getting-started" target="_blank" rel="noopener noreferrer">下载页面</a>，点击 <em>Download Now</em> 的入口，选择版本的 Tar 文件下载：</p><ul><li><a href="https://developer.nvidia.com/compute/machine-learning/tensorrt/secure/8.2.1/tars/tensorrt-8.2.1.8.linux.x86_64-gnu.cuda-11.4.cudnn8.2.tar.gz" target="_blank" rel="noopener noreferrer"><code>TensorRT 8.2 GA for Linux x86_64 and CUDA 11.0-5 TAR Package</code></a></li></ul><p>下载后得到压缩包 <code>TensorRT-${version}.tar.gz</code> ，将压缩包解压后得到同名的目录</p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code><span class="token function">tar</span> <span class="token parameter variable">-xf</span> TensorRT-<span class="token variable">${version}</span>.tar.gz
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div></li></ul><p>在系统环境变量中添加 CUDA, cuDNN,TensorRT 相关的路径(修改为真实路径<code>$xxx_HOME</code>)。添加完成后，<code>source ~/.bashrc</code> 使环境变量生效</p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># ~/.bashrc</span>
<span class="token comment"># ------ CUDA ------</span>
<span class="token assign-left variable">CUDA_VERSION</span><span class="token operator">=</span><span class="token number">11.8</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">CUDA_HOME</span><span class="token operator">=</span>/usr/local/cuda-<span class="token variable">${CUDA_VERSION}</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$PATH</span><span class="token builtin class-name">:</span><span class="token variable">$CUDA_HOME</span>/bin
<span class="token builtin class-name">export</span> <span class="token assign-left variable">LD_LIBRARY_PATH</span><span class="token operator">=</span><span class="token variable">$LD_LIBRARY_PATH</span><span class="token builtin class-name">:</span><span class="token variable">$CUDA_HOME</span>/lib64
<span class="token comment"># ------ cuDNN 8.2.1 ------</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">CUDNN_HOME</span><span class="token operator">=</span>path/to/cudnn-<span class="token operator">&lt;</span>version<span class="token operator">&gt;</span> 
<span class="token builtin class-name">export</span> <span class="token assign-left variable">LD_LIBRARY_PATH</span><span class="token operator">=</span><span class="token variable">$LD_LIBRARY_PATH</span><span class="token builtin class-name">:</span><span class="token variable">$CUDNN_HOME</span>/lib64 <span class="token comment"># 新版本为 lib 目录，建议自己检查一下</span>
<span class="token comment"># ------ TensorRT 8.2.1 ------</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">TENSORRT_HOME</span><span class="token operator">=</span>path/to/TensorRT-<span class="token operator">&lt;</span>version<span class="token operator">&gt;</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">LD_LIBRARY_PATH</span><span class="token operator">=</span><span class="token variable">$LD_LIBRARY_PATH</span><span class="token builtin class-name">:</span><span class="token variable">$TENSORRT_HOME</span>/lib
<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$PATH</span><span class="token builtin class-name">:</span><span class="token variable">$TENSORRT_HOME</span>/bin
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ol start="2"><li>安装 python相关环境</li></ol><p>参考官方文档 <a href="https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html#installing-pip" target="_blank" rel="noopener noreferrer">&quot;Python Package Index Installation&quot;</a> 安装 python 的<a href="https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html#installing-pip" target="_blank" rel="noopener noreferrer"><code>tensorrt</code></a></p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># 根据 python 版本选择对应的 .whl 文件</span>
python3 <span class="token parameter variable">-m</span> pip <span class="token function">install</span> <span class="token parameter variable">--upgrade</span> <span class="token variable">$TENSORRT_HOME</span>/python/tensorrt-<span class="token operator">&lt;</span>version<span class="token operator">&gt;</span>.whl
python3 <span class="token parameter variable">-m</span> pip <span class="token function">install</span> <span class="token parameter variable">--upgrade</span> pycuda<span class="token operator">&gt;=</span><span class="token number">2020.1</span> <span class="token comment"># 已写入 requirements.txt</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_1-tensorrt-推理-onnx-模型" tabindex="-1"><a class="header-anchor" href="#_1-tensorrt-推理-onnx-模型" aria-hidden="true">#</a> 1. TensorRT 推理 ONNX 模型</h4><p>参考官方<a href="https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#python_topics" target="_blank" rel="noopener noreferrer">Python API</a></p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code>python3 <span class="token parameter variable">-m</span> pip <span class="token function">install</span> <span class="token parameter variable">--upgrade</span> pip
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h4 id="_2-tensorrt-推理-engine-模型" tabindex="-1"><a class="header-anchor" href="#_2-tensorrt-推理-engine-模型" aria-hidden="true">#</a> 2. TensorRT 推理 Engine 模型</h4><p>参考官方文档<a href="https://docs.nvidia.com/deeplearning/tensorrt/archives/tensorrt-821/quick-start-guide/index.html#export-from-pytorch" target="_blank" rel="noopener noreferrer">&quot;Exporting To ONNX From PyTorch&quot;/&quot;Converting ONNX To A TensorRT Engine&quot;</a>这种方式的部署流程是：首先将 ONNX 模型转化为 TensorRT Engine 模型，再使用 TensorRT API 推理 Engine 模型</p><p>转换过程中需要考虑到 TensorRT 支持的 ONNX 版本，具体可以参考 <a href="https://github.com/NVIDIA/TensorRT/tree/release/8.2" target="_blank" rel="noopener noreferrer">TensorRT(8.2.1) 源码</a>中的 <a href="https://github.com/NVIDIA/TensorRT/blob/release/8.2/samples/python/efficientnet/requirements.txt" target="_blank" rel="noopener noreferrer"><code>requirements.txt</code></a> 文件，所以需要重新安装 ONNX 再重新转换</p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code>python3 <span class="token parameter variable">-m</span> pip <span class="token function">install</span> <span class="token assign-left variable">onnx</span><span class="token operator">==</span><span class="token number">1.9</span>.0 <span class="token comment"># 已写入 requirements.txt</span>
python3 export.py temp/culane.py
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>在转换之前，确保有 <code>**-INT32.onnx</code> 模型，因为 TensorRT 支持 INT32 而不支持 INT64。如果没有，可以使用 <code>onnxsim</code> 工具进行转换</p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code>python3 <span class="token parameter variable">-m</span> onnxsim weights/culane_18.onnx weights/culane_18-sim.onnx
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>上述操作都可以在电脑上完成，但是如果需要在 Jetson Nano 上推理，则需要将 onnx 转换为 Engine 模型需要在 Jetson Nano 上完成，否则会出现<a href="#issuse-tensorrt-engine_incompatible_device">&quot;<em>不匹配设备的报错</em>&quot;</a>，但是后面的步骤可以在电脑上测试没有问题再在 Jetson Nano 上部署。</p><p>Jetpack 自带的库在 <code>/usr/src</code>，因此在 Jetson Nano 的系统环境变量中添加如下内容，然后<code>source ~/.bashrc</code> 使环境变量生效</p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># ~/.bashrc</span>
<span class="token comment"># ------ CUDA 10.2 ------</span>
<span class="token assign-left variable">CUDA_VERSION</span><span class="token operator">=</span><span class="token number">10.2</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">CUDA_HOME</span><span class="token operator">=</span>/usr/local/cuda-<span class="token variable">${CUDA_VERSION}</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$PATH</span><span class="token builtin class-name">:</span><span class="token variable">$CUDA_HOME</span>/bin
<span class="token builtin class-name">export</span> <span class="token assign-left variable">LD_LIBRARY_PATH</span><span class="token operator">=</span><span class="token variable">$LD_LIBRARY_PATH</span><span class="token builtin class-name">:</span><span class="token variable">$CUDA_HOME</span>/lib64
<span class="token comment"># ------ TensorRT 8.2.1 ------</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">TENSORRT_HOME</span><span class="token operator">=</span>/usr/src/tensorrt
<span class="token builtin class-name">export</span> <span class="token assign-left variable">LD_LIBRARY_PATH</span><span class="token operator">=</span><span class="token variable">$LD_LIBRARY_PATH</span><span class="token builtin class-name">:</span><span class="token variable">$TENSORRT_HOME</span>/lib
<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$PATH</span><span class="token builtin class-name">:</span><span class="token variable">$TENSORRT_HOME</span>/bin
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>使用官方提供的转换工具进行转换，如果 TensorRT 环境配置正确，将 <code>**-INT32.onnx</code> 转化为 <code>**-INT32.engine</code>。转换过程中可能出现的bug以及解决方案记录在<a href="#TensorRT-Engine-%E8%BD%AC%E6%8D%A2%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E9%97%AE%E9%A2%98">&quot;Tensor RT Engine 转换过程中的问题&quot;</a>中，这里提供一个<a href="/program/Nvidia/TensorRT/docs/onnx2engine.html" class="">输出细节参考</a></p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code>python3 export.py configs/culane.py
trtexec <span class="token parameter variable">--verbose</span> <span class="token parameter variable">--fp16</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">--onnx</span><span class="token operator">=</span>weights/culane_18-INT32.onnx <span class="token punctuation">\</span>
  <span class="token parameter variable">--saveEngine</span><span class="token operator">=</span>weights/culane_18-INT32.engine
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><code>--workspace=N</code>: Set workspace size in megabytes (default = 16)</li><li><code>--fp16</code>: Enable fp16 precision, in addition to fp32 (default = disabled)</li><li><code>--int8</code>: Enable int8 precision, in addition to fp32 (default = disabled)</li><li><code>--verbose</code>: Use verbose logging (default = false)</li><li><code>--exportTimes=&lt;file&gt;</code> :Write the timing results in a json file (default = disabled)</li><li><code>--exportOutput=&lt;file&gt;</code>: Write the output tensors to a json file (default = disabled)</li><li><code>--exportProfile=&lt;file&gt;</code>: Write the profile information per layer in a json file (default = disabled)</li></ul><blockquote><p>实际上，NV 官方提供了 <a href="https://github.com/NVIDIA-AI-IOT/torch2trt" target="_blank" rel="noopener noreferrer"><code>torch2trt</code></a> 转换工具可以直接完成 <code>PyTroch -&gt; Engine</code>，但是在 Jetson Nano 上部署的时候，需要在 Jetson Nano 上完成模型转换，否则在实际使用时会出现<a href="#issuse-tensorrt-engine_incompatible_device">不匹配设备的报错</a>，那么将完整的 torch 项目直接安装在 Jetson Nano 上可能会遇到很多问题，因此，这里先在电脑上完成 <code>PyTroch -&gt; ONNX</code> 转换，然后将转换好的 <code>ONNX</code> 复制到 Jetson Nano 上使用 <code>trtexec</code> 完成 <code>ONNX -&gt; Engine</code> 转换，可以避免在 Jetson Nano 上安装 torch 环境和项目的一些其他环境。</p></blockquote><p>运行前需要安装 <code>pycuda</code></p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code>python3 <span class="token parameter variable">-m</span> pip <span class="token function">install</span> pycuda<span class="token operator">&gt;=</span><span class="token number">2020.1</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>然后修改 <code>deploy/infer-trtEngine.py</code> 中的 <code>TRT_MODEL_PATH</code> 为 <code>**-INT32.engine</code> 的路径，运行</p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code><span class="token builtin class-name">cd</span> deploy
python3 infer-trtEngine.py
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="问题与解决方案" tabindex="-1"><a class="header-anchor" href="#问题与解决方案" aria-hidden="true">#</a> 问题与解决方案</h2><h3 id="tensor-rt-engine-转换过程中的问题" tabindex="-1"><a class="header-anchor" href="#tensor-rt-engine-转换过程中的问题" aria-hidden="true">#</a> Tensor RT Engine 转换过程中的问题</h3><ul><li><p>报错如下</p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code><span class="token punctuation">[</span>07/13/2023-11:01:12<span class="token punctuation">]</span> <span class="token punctuation">[</span>E<span class="token punctuation">]</span> Error<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>: <span class="token punctuation">[</span>caskUtils.cpp::trtSmToCask::147<span class="token punctuation">]</span> Error Code <span class="token number">1</span>: Internal Error <span class="token punctuation">(</span>Unsupported SM: 0x809<span class="token punctuation">)</span>
<span class="token punctuation">[</span>07/13/2023-11:01:12<span class="token punctuation">]</span> <span class="token punctuation">[</span>E<span class="token punctuation">]</span> Error<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>: <span class="token punctuation">[</span>builder.cpp::buildSerializedNetwork::609<span class="token punctuation">]</span> Error Code <span class="token number">2</span>: Internal Error <span class="token punctuation">(</span>Assertion enginePtr <span class="token operator">!=</span> nullptr failed. <span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>参考 <a href="https://github.com/NVIDIA/TensorRT/issues/2727#issuecomment-1492809565" target="_blank" rel="noopener noreferrer">TensorRT #2727</a>，<code>Unsupported SM</code> 表示该版本的 TensorRT 不支持当前的 GPU 的 SM（SM是流媒体多处理器(Streaming Multiprocessor)，RTX40系列具有与以前的GPU系列不同的SM架构），需要升级 TensorRT 版本，或者选择比如RTX3080的GPU，TensorRT 8.5.1.7以上版本支持RTX40系SM</p></li><li><p>报错如下<span id="issuse-tensorrt-engine_incompatible_device"></span></p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code><span class="token punctuation">[</span>07/14/2023-11:41:43<span class="token punctuation">]</span> <span class="token punctuation">[</span>TRT<span class="token punctuation">]</span> <span class="token punctuation">[</span>E<span class="token punctuation">]</span> <span class="token number">6</span>: The engine plan <span class="token function">file</span> is generated on an incompatible device, expecting compute <span class="token number">5.3</span> got compute <span class="token number">6.1</span>, please rebuild.
<span class="token punctuation">[</span>07/14/2023-11:41:43<span class="token punctuation">]</span> <span class="token punctuation">[</span>TRT<span class="token punctuation">]</span> <span class="token punctuation">[</span>E<span class="token punctuation">]</span> <span class="token number">4</span>: <span class="token punctuation">[</span>runtime.cpp::deserializeCudaEngine::50<span class="token punctuation">]</span> Error Code <span class="token number">4</span>: Internal Error <span class="token punctuation">(</span>Engine deserialization failed.<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>这是由于 Engine 模型不是在 Jetson nano 上生成的，在 Jetson nano 上重新生成 Engine 模型即可</p></li></ul></div><!--[--><!--]--></div><footer class="page-meta"><div class="meta-item edit-link"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewBox="-43.52 -43.52 599.04 599.04" fill="currentColor"><path d="M497.9 142.1l-46.1 46.1c-4.7 4.7-12.3 4.7-17 0l-111-111c-4.7-4.7-4.7-12.3 0-17l46.1-46.1c18.7-18.7 49.1-18.7 67.9 0l60.1 60.1c18.8 18.7 18.8 49.1 0 67.9zM284.2 99.8L21.6 362.4.4 483.9c-2.9 16.4 11.4 30.6 27.8 27.8l121.5-21.3 262.6-262.6c4.7-4.7 4.7-12.3 0-17l-111-111c-4.8-4.7-12.4-4.7-17.1 0zM124.1 339.9c-5.5-5.5-5.5-14.3 0-19.8l154-154c5.5-5.5 14.3-5.5 19.8 0s5.5 14.3 0 19.8l-154 154c-5.5 5.5-14.3 5.5-19.8 0zM88 424h48v36.3l-64.5 11.3-31.1-31.1L51.7 376H88v48z"/></svg><a class="external-link meta-item-label" href="https://github.com/HenryZhuHR/henryzhuhr.github.io/edit/main/docs/program/Nvidia/TensorRT/TensorRT.md" rel="noopener noreferrer" target="_blank" aria-label="Edit this page on GitHub"><!--[--><!--]--><!----><span>Edit this page on GitHub</span><!--[--><!--]--></a></div><div class="meta-item last-updated"><span class="meta-item-label">Last Updated: </span><!----></div><!----></footer><!----><!--[--><div class="pager"><a href="/post/2023/03/02/jetson_nano/" class="prev">Previous <br><span>Powered by Jetson Nano</span></a><a href="/program/linux/linux.html" class="next">Next <br><span>Linux Go!</span></a></div><!--]--><!----></main><ul class="catalog" style="top:0px;"><li class="level-2 toc-link-什么是-tensorrt">什么是 TensorRT</li><li class="level-2 toc-link-安装">安装</li><li class="level-2 toc-link-onnx-部署">ONNX 部署</li><li class="level-2 toc-link-部署">部署</li><li class="level-3 toc-link-_1-onnx-部署">1. ONNX 部署</li><li class="level-3 toc-link-_2-tensorrt-部署">2. TensorRT 部署</li><li class="level-4 toc-link-安装-tensorrt-环境">安装 TensorRT 环境</li><li class="level-4 toc-link-_1-tensorrt-推理-onnx-模型">1. TensorRT 推理 ONNX 模型</li><li class="level-4 toc-link-_2-tensorrt-推理-engine-模型">2. TensorRT 推理 Engine 模型</li><li class="level-2 toc-link-问题与解决方案">问题与解决方案</li><li class="level-3 toc-link-tensor-rt-engine-转换过程中的问题">Tensor RT Engine 转换过程中的问题</li></ul></div><!--]--></div><div class="search-page" role="search"><span class="search-close"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" width="28" height="28" fill="currentColor"><path d="M224 416c-8.188 0-16.38-3.125-22.62-9.375l-192-192c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L224 338.8l169.4-169.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-192 192C240.4 412.9 232.2 416 224 416z"></path></svg></span><div class="gungnir-search-box"><input placeholder="$ grep ..." autocomplete="off" spellcheck="false" value><!----></div></div><div class="menu-btn-container"><div class="menu-btn-wrapper"><div class="menu-btn"><div style="" class="menu-btn-icon"><span></span><span></span><span></span></div><div style="display:none;" class="menu-text">0</div><svg class="menu-progress"><circle class="menu-border" cx="50%" cy="50%" r="48%" style="stroke-dasharray:0% 314.15926%;"></circle></svg></div><div class="menu-btn-child-wrapper"><div title="toggle color mode" class="menu-btn-child"><svg class="ov-icon" style="font-size:1.2em;display:none;" aria-hidden="true" width="19.2" height="19.2" viewBox="-43.52 -43.52 599.04 599.04" fill="currentColor"><path d="M256 160c-52.9 0-96 43.1-96 96s43.1 96 96 96 96-43.1 96-96-43.1-96-96-96zm246.4 80.5l-94.7-47.3 33.5-100.4c4.5-13.6-8.4-26.5-21.9-21.9l-100.4 33.5-47.4-94.8c-6.4-12.8-24.6-12.8-31 0l-47.3 94.7L92.7 70.8c-13.6-4.5-26.5 8.4-21.9 21.9l33.5 100.4-94.7 47.4c-12.8 6.4-12.8 24.6 0 31l94.7 47.3-33.5 100.5c-4.5 13.6 8.4 26.5 21.9 21.9l100.4-33.5 47.3 94.7c6.4 12.8 24.6 12.8 31 0l47.3-94.7 100.4 33.5c13.6 4.5 26.5-8.4 21.9-21.9l-33.5-100.4 94.7-47.3c13-6.5 13-24.7.2-31.1zm-155.9 106c-49.9 49.9-131.1 49.9-181 0-49.9-49.9-49.9-131.1 0-181 49.9-49.9 131.1-49.9 181 0 49.9 49.9 49.9 131.1 0 181z"/></svg><svg class="ov-icon" style="font-size:1.2em;display:none;" aria-hidden="true" width="19.2" height="19.2" viewBox="-43.52 -43.52 599.04 599.04" fill="currentColor"><path d="M283.211 512c78.962 0 151.079-35.925 198.857-94.792 7.068-8.708-.639-21.43-11.562-19.35-124.203 23.654-238.262-71.576-238.262-196.954 0-72.222 38.662-138.635 101.498-174.394 9.686-5.512 7.25-20.197-3.756-22.23A258.156 258.156 0 00283.211 0c-141.309 0-256 114.511-256 256 0 141.309 114.511 256 256 256z"/></svg><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewBox="-43.52 -43.52 599.04 599.04" fill="currentColor"><path d="M224 96l16-32 32-16-32-16-16-32-16 32-32 16 32 16 16 32zM80 160l26.66-53.33L160 80l-53.34-26.67L80 0 53.34 53.33 0 80l53.34 26.67L80 160zm352 128l-26.66 53.33L352 368l53.34 26.67L432 448l26.66-53.33L512 368l-53.34-26.67L432 288zm70.62-193.77L417.77 9.38C411.53 3.12 403.34 0 395.15 0c-8.19 0-16.38 3.12-22.63 9.38L9.38 372.52c-12.5 12.5-12.5 32.76 0 45.25l84.85 84.85c6.25 6.25 14.44 9.37 22.62 9.37 8.19 0 16.38-3.12 22.63-9.37l363.14-363.15c12.5-12.48 12.5-32.75 0-45.24zM359.45 203.46l-50.91-50.91 86.6-86.6 50.91 50.91-86.6 86.6z"/></svg></div><div class="menu-btn-child"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewBox="-75.52 -43.52 599.04 599.04" fill="currentColor"><path d="M207.029 381.476L12.686 187.132c-9.373-9.373-9.373-24.569 0-33.941l22.667-22.667c9.357-9.357 24.522-9.375 33.901-.04L224 284.505l154.745-154.021c9.379-9.335 24.544-9.317 33.901.04l22.667 22.667c9.373 9.373 9.373 24.569 0 33.941L240.971 381.476c-9.373 9.372-24.569 9.372-33.942 0z"/></svg></div><div class="menu-btn-child"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewBox="-75.52 -43.52 599.04 599.04" fill="currentColor"><path d="M240.971 130.524l194.343 194.343c9.373 9.373 9.373 24.569 0 33.941l-22.667 22.667c-9.357 9.357-24.522 9.375-33.901.04L224 227.495 69.255 381.516c-9.379 9.335-24.544 9.317-33.901-.04l-22.667-22.667c-9.373-9.373-9.373-24.569 0-33.941L207.03 130.525c9.372-9.373 24.568-9.373 33.941-.001z"/></svg></div><div class="menu-btn-child menu-toc-btn"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewBox="-43.52 -43.52 599.04 599.04" fill="currentColor"><path d="M48 48a48 48 0 1048 48 48 48 0 00-48-48zm0 160a48 48 0 1048 48 48 48 0 00-48-48zm0 160a48 48 0 1048 48 48 48 0 00-48-48zm448 16H176a16 16 0 00-16 16v32a16 16 0 0016 16h320a16 16 0 0016-16v-32a16 16 0 00-16-16zm0-320H176a16 16 0 00-16 16v32a16 16 0 0016 16h320a16 16 0 0016-16V80a16 16 0 00-16-16zm0 160H176a16 16 0 00-16 16v32a16 16 0 0016 16h320a16 16 0 0016-16v-32a16 16 0 00-16-16z"/></svg></div><div class="toggle-sidebar-button menu-btn-child menu-btn-sidebar" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><svg class="ov-icon" style="font-size:1.2em;" aria-hidden="true" width="19.2" height="19.2" viewBox="-1.6 -1.6 19.2 19.2" fill="currentColor"><path d="M14 2a1 1 0 011 1v10a1 1 0 01-1 1H2a1 1 0 01-1-1V3a1 1 0 011-1h12zM2 1a2 2 0 00-2 2v10a2 2 0 002 2h12a2 2 0 002-2V3a2 2 0 00-2-2H2z"/><path d="M3 4a1 1 0 011-1h2a1 1 0 011 1v8a1 1 0 01-1 1H4a1 1 0 01-1-1V4z"/></svg></div></div></div></div><footer class="footer"><span>
        &copy; <a href="https://github.com/HenryZhuHR" target="_blank">HenryZhuHR</a> 2022-today
        <br>
        Powered by <a href="https://v2.vuepress.vuejs.org" target="_blank">VuePress</a> &
        <a href="https://github.com/Renovamen/vuepress-theme-gungnir" target="_blank">Gungnir</a>
      </span></footer></div><!--]--></div>
    <script type="module" src="/assets/app.1fb5ba75.js" defer></script>
  </body>
</html>
