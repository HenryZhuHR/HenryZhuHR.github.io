import{b as e}from"./app.351d7b6c.js";import{_ as n}from"./plugin-vue_export-helper.21dcd24c.js";const a={},s=e(`<h1 id="tensorrt" tabindex="-1"><a class="header-anchor" href="#tensorrt" aria-hidden="true">#</a> TensorRT</h1><p><a href="https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#python_example_unsupported" target="_blank" rel="noopener noreferrer">TensorRT Documentation</a></p><h2 id="\u5B89\u88C5" tabindex="-1"><a class="header-anchor" href="#\u5B89\u88C5" aria-hidden="true">#</a> \u5B89\u88C5</h2><p><a href="https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html" target="_blank" rel="noopener noreferrer">Installing TensorRT</a></p><ul><li>\u786E\u4FDD NVIDIA CUDA\u2122 Toolkit \u5DF2\u7ECF\u5B89\u88C5\uFF1B\u652F\u6301\u7684 CUDA \u7248\u672C\u53EF\u4EE5\u5728 <a href="https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html#gettingstarted" target="_blank" rel="noopener noreferrer">Getting Started</a> \u4E2D\u627E\u5230</li><li>cuDNN \u662F\u53EF\u9009\u7684</li></ul><p>\u8FD9\u91CC\u91C7\u7528 <a href="https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html#installing-tar" target="_blank" rel="noopener noreferrer">Tar File Installation</a> \u7684\u5B89\u88C5\u65B9\u5F0F\uFF0C\u56E0\u4E3A\u914D\u7F6E <code>LD_LIBRARY_PATH</code> \u5373\u53EF\uFF0C\u6BD4\u8F83\u7075\u6D3B</p><p>\u4E0B\u8F7D\u5730\u5740\uFF08\u8FDB\u5165 Get Started\uFF09 https://developer.nvidia.com/tensorrt</p><p>\u89E3\u538B\u540E\u5F97\u5230 <code>TensorRT-\${version}</code></p><div class="language-text ext-text"><pre class="language-text"><code>version=&quot;8.x.x.x&quot;
arch=$(uname -m)
cuda=&quot;cuda-x.x&quot;
tar -xzvf TensorRT-\${version}.Linux.\${arch}-gnu.\${cuda}.tar.gz
</code></pre></div><p>\u8DEF\u5F84\u6DFB\u52A0\u5230\u73AF\u5883\u53D8\u91CF <code>.bashrc</code></p><div class="language-bash ext-sh"><pre class="language-bash"><code><span class="token builtin class-name">export</span> <span class="token assign-left variable">LD_LIBRARY_PATH</span><span class="token operator">=</span><span class="token variable">$LD_LIBRARY_PATH</span>:<span class="token operator">&lt;</span>path-to-TensorRT-<span class="token variable">\${version}</span>/lib<span class="token operator">&gt;</span>
</code></pre></div><div class="language-bash ext-sh"><pre class="language-bash"><code><span class="token builtin class-name">cd</span> TensorRT-<span class="token variable">\${version}</span>/python
python3 -m pip <span class="token function">install</span> tensorrt-*-cp3x-none-linux_x86_64.whl
<span class="token comment"># (optinal)</span>
python3 -m pip <span class="token function">install</span> tensorrt_lean-*-cp3x-none-linux_x86_64.whl
python3 -m pip <span class="token function">install</span> tensorrt_dispatch-*-cp3x-none-linux_x86_64.whl
</code></pre></div><h2 id="onnx-\u90E8\u7F72" tabindex="-1"><a class="header-anchor" href="#onnx-\u90E8\u7F72" aria-hidden="true">#</a> ONNX \u90E8\u7F72</h2><p><a href="https://docs.nvidia.com/deeplearning/tensorrt/quick-start-guide/index.html#ex-deploy-onnx" target="_blank" rel="noopener noreferrer">Example Deployment Using ONNX</a></p><div class="language-bash ext-sh"><pre class="language-bash"><code><span class="token assign-left variable">BATCH_SIZE</span><span class="token operator">=</span><span class="token number">64</span>
</code></pre></div>`,15);function t(r,o){return s}var i=n(a,[["render",t]]);export{i as default};
